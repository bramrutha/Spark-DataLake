# Spark Data Lake

## Project Summary

This project creates an ETL pipeline for a startup called Sparkify, a music streaming app. Sparkify has grown their user base and song database even more and want to move their data warehouse to a data lake.
This project includes building the ETL pipeline that extracts their data from S3, processes them using Spark, and loads the data back into S3 as a set of dimensional tables.

## Files in repository

**etl.py**           : Python script tha reads data from S3, processes that data using Spark, and writes them back to S3

## Project Datasets

### Song Dataset

The first dataset is a subset of real data from the Million Song Dataset. Each file is in JSON format and contains metadata about a song and the 
artist of that song.

### Log Dataset

The second dataset consists of log files in JSON format generated by this event simulator based on the songs in the dataset above. These simulate activity logs from a music streaming app based on specified configurations.
The log files in the dataset are partitioned by year and month. 


## How to run

Run the script using the below command

> python etl.py
